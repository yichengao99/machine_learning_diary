{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
    "zip_ref.extractall()\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_pecent\"):\n",
    "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SHAPE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "train_dir = \"10_food_classes_10_percent/train/\"\n",
    "test_dir = \"10_food_classes_10_percent/test/\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
    "test_datagen =ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
    "                                                         target_size = IMAGE_SHAPE,\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         class_mode = 'categorical')\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(test_dir,\n",
    "                                                       target_size = IMAGE_SHAPE,\n",
    "                                                       batch_size = BATCH_SIZE,\n",
    "                                                       class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "  log_dir = dir_name + \"/\" + experiment_name + \"/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "\n",
    "  print(f\"Saving Tensorboard log files to: {log_dir}\")\n",
    "  return tensorboard_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_url = \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\"\n",
    "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_url, num_classes=10):\n",
    "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                           trainable=False,\n",
    "                                           name = 'feature_extraction_layer',\n",
    "                                           input_shape = IMAGE_SHAPE+(3,))\n",
    "  model = tf.keras.Sequential([\n",
    "      feature_extractor_layer,\n",
    "      layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
    "  ])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n",
    "\n",
    "resnet_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer = 'Adam',\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_history = resnet_model.fit(train_data_10_percent,\n",
    "                                  epochs=5,\n",
    "                                  steps_per_epoch=len(train_data_10_percent),\n",
    "                                  validation_data=test_data,\n",
    "                                  validation_steps=len(test_data),\n",
    "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
    "                                                                         experiment_name=\"resnet50V2\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(history):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label = 'val loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label=\"val accuracy\")\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_model = create_model(model_url=efficientnet_url,\n",
    "                                 num_classes=train_data_10_percent.num_classes)\n",
    "\n",
    "efficientnet_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='Adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
    "                                              epochs=5,\n",
    "                                              steps_per_epoch=len(train_data_10_percent),\n",
    "                                              validation_data=test_data,\n",
    "                                              validation_steps = len(test_data),\n",
    "                                              callbacks = [create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
    "                                                                                       experiment_name='efficientnetB0')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curves(efficientnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
